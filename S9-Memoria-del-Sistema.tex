% Created 2025-01-18 Sat 08:13
% Intended LaTeX compiler: pdflatex
\documentclass[presentation]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{hyperref}
\setbeamertemplate{navigation symbols}{}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\nocite{*}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[backend=biber, style=apa]{biblatex}
\addbibresource{/home/iccd332-josune/expo/ExposicionArqui/bibliography.bib}
\usetheme{Berlin}
\usecolortheme{dolphin}
\usefonttheme{structurebold}
\useinnertheme{rectangles}
\useoutertheme{infolines}
\author{Martín Cusme, Celeste Gallardo, Josune Singaña, Richard Tipantiza}
\date{}
\title{S9-Memoria-del-Sistema}
\hypersetup{
 pdfauthor={Martín Cusme, Celeste Gallardo, Josune Singaña, Richard Tipantiza},
 pdftitle={S9-Memoria-del-Sistema},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.1 (Org mode 9.3)}, 
 pdflang={Spanish}}
\begin{document}

\maketitle
\begin{frame}{Outline}
\tableofcontents
\end{frame}



\section{Indicaciones}
\label{sec:org7bd62b7}


\section{Sobre este Documento}
\label{sec:org33062df}
\begin{frame}[label={sec:org51ae47d}]{Sobre este Documento}
\begin{itemize}
\item Este documento tiene la propuesta de temas a tratar y desarrollar por los estudiantes.
\item Se ha de utilizar como base la bibliografía recomendada, pero puede consultar bibliografía adicional.
\end{itemize}
\end{frame}


\section{Memoria Cache (E2, 11, 162)}
\label{sec:orgf8461de}
\begin{frame}[label={sec:org981fb3b}]{Principios Básicos de las Memorias Caché (E2,11,163)(E2,7,133)}
\begin{block}{¿Para que sirve?}
\begin{itemize}
\item El objetivo principal de la memoria caché es mejorar la velocidad de acceso a los datos almacenados, combinando el acceso rápido a datos de una memoria más cara y de alta velocidad (memoria caché) con el almacenamiento más lento pero de mayor capacidad de la memoria principal.
\end{itemize}
\end{block}

\begin{block}{Funcionamiento}
\begin{itemize}
\item La CPU transfiere palabras o bloques entre la caché y la memoria principal. La caché actúa como intermediaria rápida entre la CPU y la memoria principal, almacenando temporalmente datos que la CPU necesita frecuentemente.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}[label={sec:orgb395b8e}]{Principios Básicos de las Memorias Caché (E2,11,163)(E2,7,133)}
\begin{itemize}
\item En el modelo simple de caché (como muestra la Figura 5.1a), la CPU realiza transferencias rápidas a la caché y transferencias más lentas a la memoria principal.
\end{itemize}

\begin{center}
\includegraphics[width=.9\linewidth]{./Imagenes/captura1.png}
\end{center}
\end{frame}


\section{Principios Básicos de las Memorias Caché (E2,11,163)(E2,7,133)}
\label{sec:org0ed2177}

\begin{frame}[label={sec:org4a50c71}]{Niveles de Caché:}
\begin{itemize}
\item Se organizan en varios niveles (L1, L2, L3). A medida que se avanza en los niveles, la velocidad disminuye, pero la capacidad aumenta.
\begin{itemize}
\item Caché de Nivel 1 (L1): La más rápida y de menor capacidad.
\item Caché de Nivel 2 (L2): Un poco más lenta, pero con mayor capacidad.
\item Caché de Nivel 3 (L3): Menos rápida que L1 y L2, pero aún más rápida que la memoria principal.
\end{itemize}
\end{itemize}
\end{frame}


\section{Elementos de Diseño de la memoria Caché}
\label{sec:org48de856}

\begin{frame}[label={sec:orga06071d}]{Introducción a la Caché}
\begin{itemize}
\item La memoria caché mejora la velocidad de acceso al reducir la distancia entre el procesador y la memoria principal.
\item Los fallos de caché generan tráfico en el bus del sistema.
\end{itemize}

\begin{figure}[!h]
   \vspace{-0.1cm}
   \centering
   \includegraphics[height=4cm, width=0.8\textwidth]{./Imagenes/fig4.6.png}
   \vspace{-0.5cm} % Ajusta el espacio inferior
   \caption{Diagrama memoria caché}
   \label{fig:Representacion}
\end{figure}
\end{frame}

\begin{frame}[label={sec:org6829391}]{Parámetros de Diseño de la Caché}
\begin{block}{Parámetros Principales}
\begin{itemize}
\item La función de correspondencia, el tamaño de línea y el algoritmo de sustitución son clave para el diseño de una caché eficiente.
\item La jerarquía de cachés puede mejorar el rendimiento en aplicaciones bien optimizadas.
\end{itemize}

\begin{figure}[!h]
   \vspace{-0.1cm}
   \centering
   \includegraphics[height=4cm, width=0.8\textwidth]{./Imagenes/tabla5.1.png}
   \vspace{-0.5cm} % Ajusta el espacio inferior
   \caption{Tabla5.1}
   \label{fig:Representacion}
\end{figure}
\end{block}
\end{frame}

\begin{frame}[label={sec:org8b7805d}]{Tamaño Caché}
\begin{block}{Consideraciones de Tamaño}
\begin{itemize}
\item El tamaño de la caché impacta directamente en su velocidad y costo.
\item No existe un tamaño 'óptimo' único, ya que depende de la naturaleza de las tareas.
\end{itemize}
\begin{figure}[!h]
   \vspace{-0.1cm}
   \centering
   \includegraphics[height=4cm, width=0.8\textwidth]{./Imagenes/tabla5.2.png}
   \vspace{-0.5cm} % Ajusta el espacio inferior
   \caption{Tabla5.2}
   \label{fig:Representacion}
\end{figure}
\end{block}
\end{frame}



\begin{frame}[label={sec:orgcd13e65}]{Tipos de caché}
\begin{block}{Clasificación}
\begin{itemize}
\item La caché lógica utiliza direcciones virtuales; la física, direcciones físicas.
\item La caché lógica puede ser más rápida pero requiere mayor gestión en cambios de contexto.
\end{itemize}


\begin{figure}[!h]
   \vspace{-0.1cm}
   \centering
   \includegraphics[height=4cm, width=0.8\textwidth]{./Imagenes/fig5.png}
   \vspace{-0.5cm} % Ajusta el espacio inferior
   \caption{Clasificación Caché}
   \label{fig:Representacion}
\end{figure}
\end{block}
\end{frame}




\begin{frame}[allowframebreaks]{Función de Correspondencia (E2,11,170)(E2,7,137)}
\begin{block}{Técnicas de Organización}
Se requiere un algoritmo que permita asociar los bloques de memoria principal con las líneas de caché, ya que hay menos líneas de caché que bloques de memoria. Además, es necesario un método para identificar qué bloque de memoria está ocupando una línea específica. Para organizar la caché, se utilizan tres técnicas principales: correspondencia directa, asociativa y asociativa por conjuntos, las cuales serán explicadas junto con ejemplos concretos.
El texto explica tres técnicas para organizar la caché:

\begin{itemize}
\item \alert{\alert{Correspondencia directa:}} Cada bloque de memoria principal se asigna a una línea de caché específica. Por ejemplo, el bloque 10 se asigna a la línea 10 mod 8 = 2.

\item \alert{\alert{Correspondencia asociativa:}} Cualquier bloque puede ocupar cualquier línea de caché, lo que ofrece más flexibilidad, pero es más lento de buscar.

\item \alert{\alert{Correspondencia asociativa por conjuntos:}} La caché se divide en conjuntos, y cada bloque puede ocupar cualquier línea dentro de un conjunto específico. Por ejemplo, el bloque 10 se asigna al conjunto 10 mod 4 = 2.
\end{itemize}

Estas técnicas optimizan la asignación de memoria y el uso eficiente de la caché.
\end{block}
\end{frame}

\section{Algoritmo de Sustitución}
\label{sec:org37bcd7a}
\begin{frame}[allowframebreaks]{Algoritmo de Sustitución (E2,7,148)}
\begin{block}{Tipos de Algoritmos}
Una vez llena la caché, se debe reemplazar un bloque existente para introducir uno nuevo.
En correspondencia directa, no hay elección, ya que cada bloque tiene una línea específica.
En técnicas asociativas, se requieren algoritmos de sustitución implementados en hardware para alta velocidad.\autocite{stallings2006organización}
\begin{enumerate}
\item LRU (Least Recently Used)
\item FIFO (First-In-First-Out
\item LFU (Least Frequently Used
\item Aleatoria
\end{enumerate}
\end{block}
\end{frame}

\section{Política de escritura}
\label{sec:org0618344}
\begin{frame}[allowframebreaks]{Política de escritura}
\begin{itemize}
\item Casos de reemplazo en caché
\begin{enumerate}
\item Casos de reemplazo en caché
\item Casos de reemplazo en caché
\end{enumerate}
\item Problemas al reemplazar bloques
\begin{enumerate}
\item Acceso múltiple a la memoria principal
\item Sistemas multiprocesado
\end{enumerate}
\item Sistemas multiprocesado
\begin{enumerate}
\item Escritura inmediata
\item Postescritura
\end{enumerate}
\item Estadísticas de escritura
\item Vigilancia del bus con escritura inmediata
\item Transparencia hardware
\item Memoria excluida de caché
\end{itemize}
\end{frame}

\section{Tamaño de Linea}
\label{sec:org0a445c7}
\begin{frame}[allowframebreaks]{Tamaño de Línea}
\begin{itemize}
\item Tamaño de línea de caché:
\item Efectos al aumentar el tamaño del bloque:
\begin{enumerate}
\item Reducción de bloques en caché
\item Mayor distancia de las palabras adicionales:
\end{enumerate}
\item Relación compleja entre tamaño y tasa de aciertos
\end{itemize}
\end{frame}
\begin{frame}[allowframebreaks]{Número de Cachés (E2, 7, 150)}
Inicialmente, los sistemas contaban con una sola caché, pero con el tiempo se ha vuelto común utilizar múltiples cachés. Este diseño incluye consideraciones como el número de niveles de caché y el uso de cachés unificadas o separadas. Las cachés separadas evitan la competencia entre instrucciones y datos, mejorando el rendimiento en sistemas avanzados.

\alert{\alert{Cachés Multinivel}}
Las cachés on-chip, integradas en el procesador, reducen el uso del bus externo y mejoran el rendimiento. Normalmente, se complementan con una caché externa (L2). Los diseños más recientes incluyen múltiples niveles: L1, L2 y, en algunos casos, L3. Estas cachés adicionales, ahora frecuentemente on-chip, mejoran significativamente el rendimiento al reducir los tiempos de acceso a memoria, aunque complican aspectos como tamaño, políticas de escritura y algoritmos de reemplazo.

\alert{\alert{Caché Unificada}}
Las cachés unificadas almacenan tanto instrucciones como datos en un único espacio, maximizando la tasa de aciertos al adaptarse dinámicamente a las necesidades de ejecución. Además, solo requieren un diseño único, simplificando la implementación.

\alert{\alert{Cachés Separadas}}
Por otro lado, las cachés separadas para instrucciones y datos son preferidas en sistemas super-escalares y con segmentación de cauce. Este diseño elimina la competencia por recursos entre la ejecución de instrucciones y la unidad de datos, mejorando el rendimiento y optimizando la ejecución paralela de instrucciones.
\end{frame}

\section{Referencias}
\label{sec:orgeea22ee}
\begin{frame}[allowframebreaks]{Bibliografía}
\printbibliography
\end{frame}
\end{document}
